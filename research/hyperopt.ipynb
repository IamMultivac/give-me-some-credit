{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eeefc00-b68c-42fc-8c41-c28e0a7b06cd",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization\n",
    "\n",
    "## Rationale:\n",
    "Hyperparameter optimization is a critical step in machine learning model development. Properly tuned hyperparameters can significantly improve a model's performance and generalization. The choice of hyperparameters depends on the specific machine learning algorithm and dataset. In this study, we aim to optimize the hyperparameters of a LightGBM model, a popular gradient boosting framework, to enhance its predictive power.\n",
    "\n",
    "## Methodology:\n",
    "We conducted hyperparameter optimization using the Optuna library, which provides a powerful and efficient platform for automated hyperparameter tuning. The study involved the following steps:\n",
    "\n",
    "1. **Baseline Model**: We started by training a baseline LightGBM model with default hyperparameters. This served as a reference point for evaluating the impact of hyperparameter optimization.\n",
    "\n",
    "2. **Optuna Integration**: We utilized Optuna to search for optimal hyperparameters. Optuna employs various optimization algorithms to efficiently explore the hyperparameter space. We defined a custom objective function that evaluates the model's performance using cross-validation.\n",
    "\n",
    "3. **Parameter Search Space**: We specified a search space for hyperparameters, including learning rate, the number of leaves, minimum child samples, subsample ratio, feature fraction, and regularization terms (L1 and L2). Optuna sampled from this space to find the best combination of hyperparameters.\n",
    "\n",
    "4. **Pruning**: To expedite the optimization process, we employed pruning techniques such as Hyperband pruning. Pruning allows us to terminate poorly performing trials early, saving computational resources.\n",
    "\n",
    "5. **Integration with LightGBM**: In addition to optimizing hyperparameters, we explored LightGBM's built-in support for Optuna. By leveraging this integration, we aimed to streamline the hyperparameter tuning process and potentially achieve better results.\n",
    "\n",
    "6. **Comparison**: We compared three models: the baseline model with default hyperparameters, a model tuned with Optuna, and a model using Optuna with LightGBM integration. We evaluated their performance using appropriate metrics such as ROC-AUC, Mean Squared Error (MSE), or accuracy, depending on the specific problem.\n",
    "\n",
    "## Conclusions:\n",
    "The results of our hyperparameter optimization study yielded valuable insights into improving the LightGBM model's performance. Here are the key takeaways:\n",
    "\n",
    "- The baseline model with default hyperparameters served as a benchmark but lacked optimal performance.\n",
    "- Optuna-driven hyperparameter optimization significantly enhanced the model's predictive capabilities, achieving better results than the baseline.\n",
    "- The integration of Optuna with LightGBM provided a streamlined and efficient approach to hyperparameter tuning, potentially reducing the required computational resources.\n",
    "- The final model, with optimized hyperparameters and LightGBM integration, demonstrated superior performance, confirming the value of automated hyperparameter optimization.\n",
    "\n",
    "Overall, this hyperparameter optimization study demonstrates the importance of tuning hyperparameters for achieving the best possible model performance, and it highlights the benefits of leveraging advanced tools like Optuna and integrating them with machine learning frameworks like LightGBM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abede2b4-55fd-4731-87a3-138ed241d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm  as lgbm\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings;warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from optuna import visualization as optunaviz\n",
    "import optuna\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# local imports\n",
    "from src.learner_params import target_column, test_params, monotone_const_dict\n",
    "from utils.functions__utils import find_constraint\n",
    "\n",
    "from utils.feature_selection_lists import fw_features, boruta_features, optuna_features, ensemble_features\n",
    "\n",
    "from utils.functions__training import model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d194c60-c8b6-4657-b223-b0bc6671e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"../data/train_df.pkl\")\n",
    "validation_df = pd.read_pickle(\"../data/validation_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a33a4897-525f-4923-b861-0a79c25755cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cce30f2b2fd4b1987fcdeab22218116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from optuna.pruners import HyperbandPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.logging import set_verbosity\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    train, test = train_test_split(train_df, random_state=42, test_size=.2)\n",
    "    dtrain = lgbm.Dataset(train[boruta_features],\n",
    "                          label=train[target_column])\n",
    "\n",
    "    params = {\n",
    "        'verbose':-1,\n",
    "        'objective':\"binary\",\n",
    "        'metric':\"binary_logloss\",\n",
    "        \"monotone_constraints\":list(monotone_const_dict.values()),\n",
    "        \"boosting_type\":trial.suggest_categorical(\"boosting_type\", [\"gbdt\", \"dart\"]),\n",
    "        \"n_estimators\":trial.suggest_int(\"n_estimators\", 2000, 5000),\n",
    "        \"learning_rate\":trial.suggest_loguniform(\"learning_rate\", 1e-3,1e-1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 32, 264),\n",
    "        \"bagging_freq\":trial.suggest_int(\"bagging_freq\", 2,7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 50, 1024),\n",
    "        'subsample': trial.suggest_float('subsample', .7, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', .6, 1),\n",
    "        'lambda_l1':trial.suggest_float('lambda_l1',1e-2,10, log = True),\n",
    "        'lambda_l2':trial.suggest_float('lambda_l2',1e-2,10, log = True),\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42\n",
    "      }\n",
    "    bst = lgbm.train(params, dtrain)\n",
    "    preds = bst.predict(test[boruta_features])\n",
    "\n",
    "    score = roc_auc_score(test[target_column], preds)\n",
    "\n",
    "    return score\n",
    "\n",
    "set_verbosity(optuna.logging.ERROR)\n",
    "study = optuna.create_study(direction=\"maximize\",\n",
    "                            pruner=HyperbandPruner(),\n",
    "                            sampler=TPESampler(seed=0)\n",
    "                           )\n",
    "study.optimize(objective, n_trials=25,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c8e260-df3f-4c08-b193-559a7f448151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'dart',\n",
       " 'n_estimators': 2019,\n",
       " 'learning_rate': 0.03413575639681679,\n",
       " 'num_leaves': 213,\n",
       " 'bagging_freq': 7,\n",
       " 'min_child_samples': 296,\n",
       " 'subsample': 0.9944749447332815,\n",
       " 'colsample_bytree': 0.7617198412806786,\n",
       " 'lambda_l1': 2.2461696792562593,\n",
       " 'lambda_l2': 0.396148965326315}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6c52887-a172-4a37-bc56-0d187e347abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8710331067802403"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8d10812-e331-471c-a195-2f3bfcdd6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_one = {\n",
    "\t'learner_params': {\n",
    "\t\t'learning_rate': 0.03413575639681679,\n",
    "\t\t'n_estimators': 2019,\n",
    "\t\t'extra_params': {\n",
    "\t\t\t'objective': 'binary',\n",
    "\t\t\t'metric': 'binary_logloss',\n",
    "\t\t\t'boosting_type': 'dart',\n",
    "             'num_leaves': 213,\n",
    "             'bagging_freq': 7,\n",
    "             'min_child_samples': 296,\n",
    "             'subsample': 0.9944749447332815,\n",
    "             'colsample_bytree': 0.7617198412806786,\n",
    "             'lambda_l1': 2.2461696792562593,\n",
    "             'lambda_l2': 0.396148965326315,\n",
    "\t\t\t'monotone_constraints': list(monotone_const_dict.values()),\n",
    "\t\t\t'verbose': -1\n",
    "\t\t}\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e989ebb2-8b55-4d2a-9776-6147a014fd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-08T16:44:39 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-08T16:44:39 | INFO | Training for fold 1\n",
      "2023-10-08T16:46:09 | INFO | Training for fold 2\n",
      "2023-10-08T16:47:42 | INFO | Training for fold 3\n",
      "2023-10-08T16:49:16 | INFO | CV training finished!\n",
      "2023-10-08T16:49:16 | INFO | Training the model in the full dataset...\n",
      "2023-10-08T16:51:34 | INFO | Training process finished!\n",
      "2023-10-08T16:51:34 | INFO | Calculating metrics...\n",
      "2023-10-08T16:51:34 | INFO | Full process finished in 6.91 minutes.\n",
      "2023-10-08T16:51:34 | INFO | Saving the predict function.\n",
      "2023-10-08T16:51:34 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "challenger_one_logs = model_pipeline(train_df = train_df,\n",
    "                            validation_df = validation_df,\n",
    "                            params = best_params_one,\n",
    "                            target_column = target_column,\n",
    "                            features = boruta_features,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35090789-4e87-484f-8ec1-f6ab554fddc4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: -inf:   0%|                  | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.869076:   0%|              | 0/7 [05:11<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.869076:  14%|7    | 1/7 [05:11<31:06, 311.13s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869076:  14%|7    | 1/7 [05:11<31:06, 311.13s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869300:  14%|7    | 1/7 [10:27<31:06, 311.13s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869300:  29%|#4   | 2/7 [10:27<26:11, 314.30s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869300:  29%|#4   | 2/7 [10:27<26:11, 314.30s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869300:  29%|#4   | 2/7 [15:49<26:11, 314.30s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869300:  43%|##1  | 3/7 [15:49<21:11, 317.80s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869300:  43%|##1  | 3/7 [15:49<21:11, 317.80s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869300:  43%|##1  | 3/7 [21:12<21:11, 317.80s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869300:  57%|##8  | 4/7 [21:12<15:59, 319.96s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869300:  57%|##8  | 4/7 [21:12<15:59, 319.96s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869300:  57%|##8  | 4/7 [26:28<15:59, 319.96s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869300:  71%|###5 | 5/7 [26:28<10:36, 318.45s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869300:  71%|###5 | 5/7 [26:28<10:36, 318.45s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869300:  71%|###5 | 5/7 [31:50<10:36, 318.45s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869300:  86%|####2| 6/7 [31:50<05:19, 319.55s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869300:  86%|####2| 6/7 [31:50<05:19, 319.55s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869369:  86%|####2| 6/7 [37:08<05:19, 319.55s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.869369: 100%|#####| 7/7 [37:08<00:00, 318.36s/it]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.869369:   0%|                   | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.869369:   0%|                   | 0/20 [05:51<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.869369:   5%|4       | 1/20 [05:51<1:51:15, 351.35s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869369:   5%|4       | 1/20 [05:51<1:51:15, 351.35s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869503:   5%|4       | 1/20 [10:01<1:51:15, 351.35s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869503:  10%|8       | 2/20 [10:01<1:27:36, 292.03s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869503:  10%|8       | 2/20 [10:01<1:27:36, 292.03s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869503:  10%|8       | 2/20 [15:53<1:27:36, 292.03s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869503:  15%|#2      | 3/20 [15:53<1:30:29, 319.36s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869503:  15%|#2      | 3/20 [15:53<1:30:29, 319.36s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  15%|#2      | 3/20 [19:13<1:30:29, 319.36s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  20%|#6      | 4/20 [19:13<1:12:33, 272.11s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  20%|#6      | 4/20 [19:13<1:12:33, 272.11s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  20%|#6      | 4/20 [21:10<1:12:33, 272.11s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  25%|##5       | 5/20 [21:10<54:01, 216.08s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  25%|##5       | 5/20 [21:10<54:01, 216.08s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  25%|##5       | 5/20 [24:27<54:01, 216.08s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  30%|###       | 6/20 [24:27<48:55, 209.69s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  30%|###       | 6/20 [24:27<48:55, 209.69s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  30%|###       | 6/20 [30:19<48:55, 209.69s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  35%|###5      | 7/20 [30:19<55:30, 256.21s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  35%|###5      | 7/20 [30:19<55:30, 256.21s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  35%|###5      | 7/20 [36:11<55:30, 256.21s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  40%|####      | 8/20 [36:11<57:20, 286.73s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  40%|####      | 8/20 [36:11<57:20, 286.73s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  40%|####      | 8/20 [42:01<57:20, 286.73s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  45%|####5     | 9/20 [42:01<56:12, 306.62s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  45%|####5     | 9/20 [42:01<56:12, 306.62s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  45%|####5     | 9/20 [47:53<56:12, 306.62s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  50%|####5    | 10/20 [47:53<53:26, 320.67s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  50%|####5    | 10/20 [47:53<53:26, 320.67s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  50%|####5    | 10/20 [53:35<53:26, 320.67s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  55%|####9    | 11/20 [53:35<49:03, 327.07s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  55%|####9    | 11/20 [53:35<49:03, 327.07s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  55%|####9    | 11/20 [59:25<49:03, 327.07s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  60%|#####3   | 12/20 [59:25<44:32, 334.01s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  60%|#####3   | 12/20 [59:25<44:32, 334.01s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  60%|####2  | 12/20 [1:03:29<44:32, 334.01s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  65%|####5  | 13/20 [1:03:29<35:46, 306.68s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  65%|####5  | 13/20 [1:03:29<35:46, 306.68s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  65%|####5  | 13/20 [1:09:19<35:46, 306.68s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  70%|####8  | 14/20 [1:09:19<31:59, 319.85s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  70%|####8  | 14/20 [1:09:19<31:59, 319.85s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  70%|####8  | 14/20 [1:11:16<31:59, 319.85s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  75%|#####2 | 15/20 [1:11:16<21:33, 258.63s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  75%|#####2 | 15/20 [1:11:16<21:33, 258.63s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  75%|#####2 | 15/20 [1:16:59<21:33, 258.63s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  80%|#####6 | 16/20 [1:16:59<18:56, 284.12s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  80%|#####6 | 16/20 [1:16:59<18:56, 284.12s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  80%|#####6 | 16/20 [1:21:52<18:56, 284.12s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  85%|#####9 | 17/20 [1:21:52<14:20, 286.75s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  85%|#####9 | 17/20 [1:21:52<14:20, 286.75s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  85%|#####9 | 17/20 [1:27:45<14:20, 286.75s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  90%|######3| 18/20 [1:27:45<10:13, 306.62s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  90%|######3| 18/20 [1:27:45<10:13, 306.62s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  90%|######3| 18/20 [1:32:53<10:13, 306.62s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  95%|######6| 19/20 [1:32:53<05:07, 307.05s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  95%|######6| 19/20 [1:32:53<05:07, 307.05s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607:  95%|######6| 19/20 [1:38:44<05:07, 307.05s/it]\u001b[A\n",
      "num_leaves, val_score: 0.869607: 100%|#######| 20/20 [1:38:44<00:00, 296.24s/it]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.869607:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.869607:   0%|                      | 0/10 [03:11<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.869607:  10%|#3           | 1/10 [03:11<28:41, 191.26s/it]\u001b[A\n",
      "bagging, val_score: 0.869607:  10%|#3           | 1/10 [03:11<28:41, 191.26s/it]\u001b[A\n",
      "bagging, val_score: 0.869607:  10%|#3           | 1/10 [06:26<28:41, 191.26s/it]\u001b[A\n",
      "bagging, val_score: 0.869607:  20%|##6          | 2/10 [06:26<25:50, 193.76s/it]\u001b[A\n",
      "bagging, val_score: 0.869607:  20%|##6          | 2/10 [06:26<25:50, 193.76s/it]\u001b[A\n",
      "bagging, val_score: 0.869607:  20%|##6          | 2/10 [09:43<25:50, 193.76s/it]\u001b[A\n",
      "bagging, val_score: 0.869607:  30%|###9         | 3/10 [09:43<22:46, 195.22s/it]\u001b[A\n",
      "bagging, val_score: 0.869607:  30%|###9         | 3/10 [09:43<22:46, 195.22s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  30%|###9         | 3/10 [13:00<22:46, 195.22s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  40%|#####2       | 4/10 [13:00<19:33, 195.66s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  40%|#####2       | 4/10 [13:00<19:33, 195.66s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  40%|#####2       | 4/10 [16:19<19:33, 195.66s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  50%|######5      | 5/10 [16:19<16:25, 197.12s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  50%|######5      | 5/10 [16:19<16:25, 197.12s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  50%|######5      | 5/10 [19:42<16:25, 197.12s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  60%|#######8     | 6/10 [19:42<13:16, 199.02s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  60%|#######8     | 6/10 [19:42<13:16, 199.02s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  60%|#######8     | 6/10 [23:01<13:16, 199.02s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  70%|#########1   | 7/10 [23:01<09:56, 198.86s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  70%|#########1   | 7/10 [23:01<09:56, 198.86s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  70%|#########1   | 7/10 [26:22<09:56, 198.86s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  80%|##########4  | 8/10 [26:22<06:39, 199.58s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  80%|##########4  | 8/10 [26:22<06:39, 199.58s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  80%|##########4  | 8/10 [29:43<06:39, 199.58s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  90%|###########7 | 9/10 [29:43<03:20, 200.01s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  90%|###########7 | 9/10 [29:43<03:20, 200.01s/it]\u001b[A\n",
      "bagging, val_score: 0.869692:  90%|###########7 | 9/10 [33:04<03:20, 200.01s/it]\u001b[A\n",
      "bagging, val_score: 0.869692: 100%|############| 10/10 [33:04<00:00, 198.44s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:   0%|       | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:   0%|       | 0/6 [03:16<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:  17%|1| 1/6 [03:16<16:24, 196.80s/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:  17%|1| 1/6 [03:16<16:24, 196.80s/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:  17%|1| 1/6 [06:34<16:24, 196.80s/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:  33%|3| 2/6 [06:34<13:09, 197.26s/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:  33%|3| 2/6 [06:34<13:09, 197.26s/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:  33%|3| 2/6 [09:50<13:09, 197.26s/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:  50%|5| 3/6 [09:50<09:50, 196.79s/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:  50%|5| 3/6 [09:50<09:50, 196.79s/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:  50%|5| 3/6 [13:08<09:50, 196.79s/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:  67%|6| 4/6 [13:08<06:34, 197.04s/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:  67%|6| 4/6 [13:08<06:34, 197.04s/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:  67%|6| 4/6 [16:24<06:34, 197.04s/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:  83%|8| 5/6 [16:24<03:16, 196.70s/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:  83%|8| 5/6 [16:24<03:16, 196.70s/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692:  83%|8| 5/6 [19:38<03:16, 196.70s/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.869692: 100%|#| 6/6 [19:38<00:00, 196.44s/\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.869692:   0%|       | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.869783:   0%|       | 0/20 [03:14<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.869783:   5%| | 1/20 [03:14<1:01:35, 194.48\u001b[A\n",
      "regularization_factors, val_score: 0.869783:   5%| | 1/20 [03:14<1:01:35, 194.48\u001b[A\n",
      "regularization_factors, val_score: 0.869863:   5%| | 1/20 [06:34<1:01:35, 194.48\u001b[A\n",
      "regularization_factors, val_score: 0.869863:  10%|1| 2/20 [06:34<59:23, 197.98s/\u001b[A\n",
      "regularization_factors, val_score: 0.869863:  10%|1| 2/20 [06:34<59:23, 197.98s/\u001b[A\n",
      "regularization_factors, val_score: 0.869902:  10%|1| 2/20 [09:49<59:23, 197.98s/\u001b[A\n",
      "regularization_factors, val_score: 0.869902:  15%|1| 3/20 [09:49<55:37, 196.33s/\u001b[A\n",
      "regularization_factors, val_score: 0.869902:  15%|1| 3/20 [09:49<55:37, 196.33s/\u001b[A\n",
      "regularization_factors, val_score: 0.869902:  15%|1| 3/20 [13:06<55:37, 196.33s/\u001b[A\n",
      "regularization_factors, val_score: 0.869902:  20%|2| 4/20 [13:06<52:29, 196.83s/\u001b[A\n",
      "regularization_factors, val_score: 0.869902:  20%|2| 4/20 [13:06<52:29, 196.83s/\u001b[A\n",
      "regularization_factors, val_score: 0.869902:  20%|2| 4/20 [16:23<52:29, 196.83s/\u001b[A\n",
      "regularization_factors, val_score: 0.869902:  25%|2| 5/20 [16:23<49:12, 196.85s/\u001b[A\n",
      "regularization_factors, val_score: 0.869902:  25%|2| 5/20 [16:23<49:12, 196.85s/\u001b[A\n",
      "regularization_factors, val_score: 0.869902:  25%|2| 5/20 [19:39<49:12, 196.85s/\u001b[A\n",
      "regularization_factors, val_score: 0.869902:  30%|3| 6/20 [19:39<45:52, 196.60s/\u001b[A\n",
      "regularization_factors, val_score: 0.869902:  30%|3| 6/20 [19:39<45:52, 196.60s/\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  30%|3| 6/20 [22:54<45:52, 196.60s/\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  35%|3| 7/20 [22:54<42:26, 195.90s/\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  35%|3| 7/20 [22:54<42:26, 195.90s/\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  35%|3| 7/20 [26:08<42:26, 195.90s/\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  40%|4| 8/20 [26:08<39:02, 195.22s/\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  40%|4| 8/20 [26:08<39:02, 195.22s/\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  40%|4| 8/20 [29:19<39:02, 195.22s/\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  45%|4| 9/20 [29:19<35:34, 194.03s/\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  45%|4| 9/20 [29:19<35:34, 194.03s/\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  45%|4| 9/20 [32:31<35:34, 194.03s/\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  50%|5| 10/20 [32:31<32:13, 193.35s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  50%|5| 10/20 [32:31<32:13, 193.35s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  50%|5| 10/20 [35:42<32:13, 193.35s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  55%|5| 11/20 [35:42<28:54, 192.70s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  55%|5| 11/20 [35:42<28:54, 192.70s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  55%|5| 11/20 [38:54<28:54, 192.70s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  60%|6| 12/20 [38:54<25:39, 192.38s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  60%|6| 12/20 [38:54<25:39, 192.38s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  60%|6| 12/20 [42:04<25:39, 192.38s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  65%|6| 13/20 [42:04<22:22, 191.75s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  65%|6| 13/20 [42:04<22:22, 191.75s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  65%|6| 13/20 [45:17<22:22, 191.75s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  70%|7| 14/20 [45:17<19:12, 192.02s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  70%|7| 14/20 [45:17<19:12, 192.02s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  70%|7| 14/20 [48:29<19:12, 192.02s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  75%|7| 15/20 [48:29<16:00, 192.19s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  75%|7| 15/20 [48:29<16:00, 192.19s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  75%|7| 15/20 [51:42<16:00, 192.19s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  80%|8| 16/20 [51:42<12:49, 192.31s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  80%|8| 16/20 [51:42<12:49, 192.31s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  80%|8| 16/20 [54:55<12:49, 192.31s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  85%|8| 17/20 [54:55<09:37, 192.46s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  85%|8| 17/20 [54:55<09:37, 192.46s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  85%|8| 17/20 [58:07<09:37, 192.46s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  90%|9| 18/20 [58:07<06:24, 192.49s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  90%|9| 18/20 [58:07<06:24, 192.49s\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  90%|9| 18/20 [1:01:19<06:24, 192.4\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  95%|9| 19/20 [1:01:19<03:12, 192.3\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  95%|9| 19/20 [1:01:19<03:12, 192.3\u001b[A\n",
      "regularization_factors, val_score: 0.869979:  95%|9| 19/20 [1:04:30<03:12, 192.3\u001b[A\n",
      "regularization_factors, val_score: 0.869979: 100%|#| 20/20 [1:04:30<00:00, 193.5\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.869979:   0%|              | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.869979:   0%|              | 0/5 [03:09<?, ?it/s]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.869979:  20%|#    | 1/5 [03:09<12:36, 189.20s/it]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.869979:  20%|#    | 1/5 [03:09<12:36, 189.20s/it]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.869979:  20%|#    | 1/5 [06:16<12:36, 189.20s/it]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.869979:  40%|##   | 2/5 [06:16<09:25, 188.35s/it]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.869979:  40%|##   | 2/5 [06:16<09:25, 188.35s/it]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.869979:  40%|##   | 2/5 [09:24<09:25, 188.35s/it]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.869979:  60%|###  | 3/5 [09:24<06:16, 188.13s/it]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.869979:  60%|###  | 3/5 [09:24<06:16, 188.13s/it]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.869979:  60%|###  | 3/5 [12:33<06:16, 188.13s/it]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.869979:  80%|#### | 4/5 [12:33<03:08, 188.18s/it]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.869979:  80%|#### | 4/5 [12:33<03:08, 188.18s/it]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.869979:  80%|#### | 4/5 [15:40<03:08, 188.18s/it]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.869979: 100%|#####| 5/5 [15:40<00:00, 188.14s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'objective': 'binary', 'metric': 'auc', 'verbosity': -1, 'boosting_type': 'dart', 'monotone_constraints': [-1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0], 'learning_rate': 0.0287322553886959, 'feature_pre_filter': False, 'lambda_l1': 1.3295519436441523e-07, 'lambda_l2': 8.532928874611256, 'num_leaves': 9, 'feature_fraction': 0.7, 'bagging_fraction': 0.9638644341977596, 'bagging_freq': 1, 'min_child_samples': 20, 'num_iterations': 3073}\n",
      "CPU times: user 1d 1h 4min 48s, sys: 51min 18s, total: 1d 1h 56min 6s\n",
      "Wall time: 4h 28min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import optuna.integration.lightgbm as lgb\n",
    "\n",
    "from lightgbm import early_stopping\n",
    "from lightgbm import log_evaluation\n",
    "\n",
    "train, test = train_test_split(train_df, random_state=42, test_size=.2)\n",
    "dtrain = lgbm.Dataset(train[fw_features], label=train[target_column])\n",
    "dval = lgb.Dataset(test[fw_features], label=test[target_column])\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"dart\",\n",
    "    'monotone_constraints': list(monotone_const_dict.values()),\n",
    "    \"n_estimators\":3073,\n",
    "    \"learning_rate\": 0.0287322553886959\n",
    "}\n",
    "\n",
    "bst = lgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    valid_sets=[dtrain, dval],\n",
    "    callbacks=[early_stopping(150)],\n",
    ")\n",
    "\n",
    "preds = bst.predict(test[fw_features],num_iteration=bst.best_iteration)\n",
    "score = roc_auc_score(test[target_column], preds)\n",
    "\n",
    "best_params = bst.params\n",
    "print(\"Best params:\", best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e1b1aae-6bbb-4e20-a306-ecfdf3db4bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'metric': 'auc',\n",
       " 'verbosity': -1,\n",
       " 'boosting_type': 'dart',\n",
       " 'monotone_constraints': [-1.0,\n",
       "  -1.0,\n",
       "  -1.0,\n",
       "  -1.0,\n",
       "  -1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  -1.0,\n",
       "  -1.0,\n",
       "  -1.0,\n",
       "  -1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  -1.0,\n",
       "  -1.0,\n",
       "  1.0,\n",
       "  -1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  -1.0,\n",
       "  1.0],\n",
       " 'learning_rate': 0.0287322553886959,\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 1.3295519436441523e-07,\n",
       " 'lambda_l2': 8.532928874611256,\n",
       " 'num_leaves': 9,\n",
       " 'feature_fraction': 0.7,\n",
       " 'bagging_fraction': 0.9638644341977596,\n",
       " 'bagging_freq': 1,\n",
       " 'min_child_samples': 20,\n",
       " 'num_iterations': 3073}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfa15998-7206-4cf9-a229-fba027b86c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.OrderedDict,\n",
       "            {'valid_0': OrderedDict([('auc', 0.8707383205856697)]),\n",
       "             'valid_1': OrderedDict([('auc', 0.8699786100128452)])})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "226f72ef-6f81-4461-bb39-a0bcf30d5ab5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b05bc6e648419bae40129f265ba74e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from optuna.logging import set_verbosity\n",
    "import optuna\n",
    "from optuna.pruners import HyperbandPruner\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    train, test = train_test_split(train_df, random_state=42, test_size=.2)\n",
    "    dtrain = lgbm.Dataset(train[boruta_features], label=train[target_column])\n",
    "\n",
    "    params = {\n",
    "        'verbose':-1,\n",
    "        'objective':\"binary\",\n",
    "        'metric':\"binary_logloss\",\n",
    "         'boosting_type': 'gbdt',\n",
    "        'lambda_l1': 4.937571654251182,\n",
    "         'lambda_l2': 1.3115176714127536e-08,\n",
    "         'num_leaves': 50,\n",
    "         'feature_fraction': 0.8999999999999999,\n",
    "         'bagging_fraction': 1.0,\n",
    "         'bagging_freq': 0,\n",
    "         'min_child_samples': 20,\n",
    "         \"n_estimators\":trial.suggest_int(\"n_estimators\", 2000, 10000),\n",
    "         \"learning_rate\":trial.suggest_loguniform(\"learning_rate\", 1e-3,1e-1),\n",
    "         'n_jobs': -1,\n",
    "         'random_state': 42\n",
    "      }\n",
    "    bst = lgbm.train(params, dtrain)\n",
    "    preds = bst.predict(test[boruta_features])\n",
    "\n",
    "    score = roc_auc_score(test[target_column], preds)\n",
    "\n",
    "    return score\n",
    "\n",
    "set_verbosity(optuna.logging.ERROR)\n",
    "study = optuna.create_study(direction=\"maximize\",\n",
    "                            pruner=HyperbandPruner(),\n",
    "                            sampler=TPESampler(seed=0)\n",
    "                           )\n",
    "study.optimize(objective, n_trials=50,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ba9602-ca40-4fb5-b91c-8ec7e7ac9734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 5926, 'learning_rate': 0.005603627873630697}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55093bc1-8d3e-41de-848d-2c25a72d39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_two = {\n",
    "\t'learner_params': {\n",
    "\t\t'n_estimators': 3073, \n",
    "        'learning_rate': 0.0287322553886959,\n",
    "\t\t'extra_params': {\n",
    "\t\t\t'objective': 'binary',\n",
    "\t\t\t'metric': 'binary_logloss',\n",
    "\t\t\t'boosting_type': 'dart',\n",
    "\t\t\t 'lambda_l1': 1.3295519436441523e-07,\n",
    "             'lambda_l2': 8.532928874611256,\n",
    "             'num_leaves': 9,\n",
    "             'feature_fraction': 0.7,\n",
    "             'bagging_fraction': 0.9638644341977596,\n",
    "             'bagging_freq': 1,\n",
    "             'min_child_samples': 20,\n",
    "\t\t\t'n_jobs': -1,\n",
    "\t\t\t'random_state': 42,\n",
    "\t\t\t'monotone_constraints': list(monotone_const_dict.values()),\n",
    "\t\t\t'verbose': -1\n",
    "\t\t}\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37e75df6-e7eb-45ad-bac6-0e4f89369e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-08T16:52:05 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-08T16:52:05 | INFO | Training for fold 1\n",
      "2023-10-08T16:53:42 | INFO | Training for fold 2\n",
      "2023-10-08T16:55:21 | INFO | Training for fold 3\n",
      "2023-10-08T16:57:00 | INFO | CV training finished!\n",
      "2023-10-08T16:57:00 | INFO | Training the model in the full dataset...\n",
      "2023-10-08T16:59:21 | INFO | Training process finished!\n",
      "2023-10-08T16:59:21 | INFO | Calculating metrics...\n",
      "2023-10-08T16:59:21 | INFO | Full process finished in 7.27 minutes.\n",
      "2023-10-08T16:59:21 | INFO | Saving the predict function.\n",
      "2023-10-08T16:59:21 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "challenger_two_logs = model_pipeline(train_df = train_df,\n",
    "                            validation_df = validation_df,\n",
    "                            params = best_params_two,\n",
    "                            target_column = target_column,\n",
    "                            features = boruta_features,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "093c8699-adb4-4736-84df-2d167691e073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-08T16:59:21 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-08T16:59:21 | INFO | Training for fold 1\n",
      "2023-10-08T16:59:31 | INFO | Training for fold 2\n",
      "2023-10-08T16:59:41 | INFO | Training for fold 3\n",
      "2023-10-08T16:59:51 | INFO | CV training finished!\n",
      "2023-10-08T16:59:51 | INFO | Training the model in the full dataset...\n",
      "2023-10-08T17:00:05 | INFO | Training process finished!\n",
      "2023-10-08T17:00:05 | INFO | Calculating metrics...\n",
      "2023-10-08T17:00:05 | INFO | Full process finished in 0.73 minutes.\n",
      "2023-10-08T17:00:05 | INFO | Saving the predict function.\n",
      "2023-10-08T17:00:05 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "mc_params = deepcopy(test_params)\n",
    "mc_params[\"learner_params\"][\"extra_params\"][\"monotone_constraints\"] = list(monotone_const_dict.values())\n",
    "base_logs = model_pipeline(train_df = train_df,\n",
    "                            validation_df = validation_df,\n",
    "                            params = mc_params,\n",
    "                            target_column = target_column,\n",
    "                            features = boruta_features,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fb89c7-bd9a-4893-a9d1-a11ad3bc5b26",
   "metadata": {},
   "source": [
    "## Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e3d57dc-fda9-4276-9407-411ffad60776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>out_of_fold</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boruta + Optuna integration</th>\n",
       "      <td>0.864788</td>\n",
       "      <td>0.867128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boruta vanilla</th>\n",
       "      <td>0.864468</td>\n",
       "      <td>0.866720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boruta + Optuna base</th>\n",
       "      <td>0.864924</td>\n",
       "      <td>0.866677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             out_of_fold  validation\n",
       "boruta + Optuna integration     0.864788    0.867128\n",
       "boruta vanilla                  0.864468    0.866720\n",
       "boruta + Optuna base            0.864924    0.866677"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics  ={}\n",
    "models = [base_logs, challenger_one_logs, challenger_two_logs]\n",
    "names = [\"boruta vanilla\", \"boruta + Optuna base\", \"boruta + Optuna integration\"]\n",
    "\n",
    "for model, name in zip(models, names):\n",
    "    model_metrics[f\"{name}\"] = model[\"metrics\"][\"roc_auc\"]\n",
    "pd.DataFrame(model_metrics).T.sort_values(by = \"validation\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cda6ba8-3479-45d7-9a6e-0394d928dc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
