{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ae3f328-2f8c-488f-ab1d-2cd7bdb5e3e2",
   "metadata": {},
   "source": [
    "# Train model pipeline\n",
    "\n",
    "## Rationale:\n",
    "Based on the previous experiments we are to train the model for the competition's submissions. We are to use the full dataset ```train``` + ```test``` + ```validation``` to train the final models and in the case of the ensemble models, the ```out of fold``` predictions. \n",
    "\n",
    "## Methodology:\n",
    "We are to train each model with the optimized hyperparamters and use the out of fold predictions of each to train two final stackers:\n",
    "\n",
    "1. A linear model trained on the model's predictions.\n",
    "2. A NN model trained on the model's predictions.\n",
    "\n",
    "Then we will save the predictions on the private dataset and use them for the final submissions.\n",
    "\n",
    "## Conclusions:\n",
    "\n",
    "1. **Consistency in Model Performance**: The private and public scores for the different models are very close to each other, indicating consistent performance.\n",
    "\n",
    "2. **Stacking Models**: \"Stacking MLP,\" \"Stacking LR,\" and \"Stacking AVG\" models perform similarly with scores around 0.7980 (private) and 0.8000 (public).\n",
    "\n",
    "3. **Boruta + Optuna**: \"Boruta + Optuna\" model performs competitively with scores of 0.7980 (private) and 0.7992 (public).\n",
    "\n",
    "4. **Model Selection**: Consider factors beyond just performance, including model complexity, interpretability, training time, and resource requirements.\n",
    "\n",
    "5. **Ensemble and Model Tuning**: Stacking models and combining feature selection methods with hyperparameter optimization can be effective strategies.\n",
    "\n",
    "6. **Further Investigation**: Explore feature importance, model interpretability, and experiment with different model architectures or hyperparameters.\n",
    "\n",
    "In summary, while performance differences are subtle, choose a model considering practical aspects and continue experimentation for optimization.\n",
    "\n",
    "\n",
    "| Model             | Private Score | Public Score |\n",
    "|-------------------|---------------|--------------|\n",
    "| Stacking MLP      | 0.7983        | 0.8006       |\n",
    "| Stacking LR       | 0.7981        | 0.8005       |\n",
    "| Stacking AVG      | 0.7980        | 0.8002       |\n",
    "| Boruta + Optuna   | 0.7980        | 0.7992       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "670e0564-43f7-4a79-b742-e1d8edee895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings;warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import cloudpickle as cp\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import joblib\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# local imports\n",
    "from src.learner_params import target_column,space_column, MODEL_PARAMS\n",
    "\n",
    "from utils.functions__training import model_pipeline, lgbm_classification_learner\n",
    "from src.learner_params import params_all, params_ensemble, params_fw, params_original\n",
    "from utils.feature_selection_lists import fw_features, boruta_features, ensemble_features\n",
    "from utils.features_lists import all_features_list, base_features\n",
    "from utils.functions__utils import train_binary\n",
    "from utils.functions__utils import find_constraint\n",
    "\n",
    "columns = ['prediction_MrMr',\n",
    " 'prediction_base',\n",
    " 'prediction_all_features',\n",
    " 'prediction_boruta',\n",
    " 'prediction_ensemble']\n",
    "\n",
    "names = [\"all_features\",\n",
    "        \"boruta\",\n",
    "        \"MrMr\",\n",
    "        \"base\", \n",
    "        \"ensemble\"\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c0a1613-6990-451e-9348-1779e7b8d739",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"../data/train_df.pkl\")\n",
    "validation_df = pd.read_pickle(\"../data/validation_df.pkl\")\n",
    "test_df= pd.read_pickle(\"../data/test_df.pkl\")\n",
    "\n",
    "private_df= pd.read_pickle(\"../data/private_df.pkl\")\n",
    "\n",
    "data = pd.concat([train_df, test_df, validation_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e97adf0-204d-4dce-8fe6-58be20b469a8",
   "metadata": {},
   "source": [
    "### Monotone constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c76dcc9-3916-44a9-9bae-27a2c6ca8d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_monotone_const_dict = {}\n",
    "for feature in ensemble_features:\n",
    "    aux = find_constraint(train_df, feature, target_column)\n",
    "    ensemble_monotone_const_dict[feature] = aux\n",
    "\n",
    "all_monotone_const_dict = {}\n",
    "for feature in all_features_list:\n",
    "    aux = find_constraint(train_df, feature, target_column)\n",
    "    all_monotone_const_dict[feature] = aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45a43f68-640d-405d-95b0-00e6c3ad9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_params_mc = deepcopy(params_ensemble)\n",
    "ensemble_params_mc[\"learner_params\"][\"extra_params\"][\"monotone_constraints\"] = list(ensemble_monotone_const_dict.values())\n",
    "\n",
    "all_params_mc = deepcopy(params_all)\n",
    "all_params_mc[\"learner_params\"][\"extra_params\"][\"monotone_constraints\"] = list(all_monotone_const_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4d1ae6-8676-4bf1-b705-069447dbd251",
   "metadata": {},
   "source": [
    "### Train the best model (Boruta + Optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61cfe1b3-64cb-4fc9-85ee-37351726ecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11T12:52:52 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-11T12:52:52 | INFO | Training for fold 1\n",
      "2023-10-11T12:54:36 | INFO | Training for fold 2\n",
      "2023-10-11T12:56:24 | INFO | Training for fold 3\n",
      "2023-10-11T12:58:19 | INFO | CV training finished!\n",
      "2023-10-11T12:58:19 | INFO | Training the model in the full dataset...\n",
      "2023-10-11T13:00:58 | INFO | Training process finished!\n",
      "2023-10-11T13:00:58 | INFO | Calculating metrics...\n",
      "2023-10-11T13:00:58 | INFO | Full process finished in 8.10 minutes.\n",
      "2023-10-11T13:00:58 | INFO | Saving the predict function.\n",
      "2023-10-11T13:00:58 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "save_estimator_path = \"../model_files/final__boruta_learner.pkl\"\n",
    "model_logs = model_pipeline(train_df = data,\n",
    "                            validation_df = validation_df,\n",
    "                            params = MODEL_PARAMS,\n",
    "                            target_column = target_column,\n",
    "                            features = boruta_features,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False\n",
    "                          )\n",
    "with open(save_estimator_path, \"wb\") as context:\n",
    "    cp.dump(model_logs[\"lgbm_classification_learner\"], context)\n",
    "    \n",
    "model_logs[\"data\"][\"oof_df\"].to_pickle(\"../data/final__boruta_oof_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32a59194-fb6b-446c-9c67-6fc73014e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "private_predictions = model_logs[\"lgbm_classification_learner\"][\"predict_fn\"](private_df, apply_shap = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "491dd0fc-083a-4932-836a-2076c9e1938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/submissions/private_predictions_hyperopt2s.csv\"\n",
    "private_predictions = private_predictions[[space_column, \"prediction\"]]\n",
    "private_predictions = private_predictions.rename(columns = {\"prediction\":\"Probability\"})\n",
    "private_predictions.to_csv(path, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a71892-873a-4551-b00b-2a203fb17c72",
   "metadata": {},
   "source": [
    "### Train the ensembles:\n",
    "\n",
    "1. Average prediction\n",
    "2. Logistic regression\n",
    "3. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87b32c14-7d01-42ba-85f1-a9948d1733f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11T13:01:01 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-11T13:01:01 | INFO | Training for fold 1\n",
      "2023-10-11T13:01:45 | INFO | Training for fold 2\n",
      "2023-10-11T13:02:29 | INFO | Training for fold 3\n",
      "2023-10-11T13:03:14 | INFO | CV training finished!\n",
      "2023-10-11T13:03:14 | INFO | Training the model in the full dataset...\n",
      "2023-10-11T13:04:10 | INFO | Training process finished!\n",
      "2023-10-11T13:04:10 | INFO | Calculating metrics...\n",
      "2023-10-11T13:04:10 | INFO | Full process finished in 3.16 minutes.\n",
      "2023-10-11T13:04:10 | INFO | Saving the predict function.\n",
      "2023-10-11T13:04:10 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "save_estimator_path = \"../model_files/final__fw_learner.pkl\"\n",
    "fw_full_logs = model_pipeline(train_df = data,\n",
    "                            validation_df = validation_df,\n",
    "                            params = params_fw,\n",
    "                            target_column = target_column,\n",
    "                            features = fw_features,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False,\n",
    "                            save_estimator_path=None\n",
    "                          )\n",
    "\n",
    "with open(save_estimator_path, \"wb\") as context:\n",
    "    cp.dump(fw_full_logs[\"lgbm_classification_learner\"], context)\n",
    "\n",
    "\n",
    "fw_full_logs[\"data\"][\"oof_df\"].to_pickle(\"../data/final__fw_oof_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0e48705-3bf1-4e2c-9b36-35a5f4e485b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11T13:04:11 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-11T13:04:11 | INFO | Training for fold 1\n",
      "2023-10-11T13:04:37 | INFO | Training for fold 2\n",
      "2023-10-11T13:05:04 | INFO | Training for fold 3\n",
      "2023-10-11T13:05:30 | INFO | CV training finished!\n",
      "2023-10-11T13:05:30 | INFO | Training the model in the full dataset...\n",
      "2023-10-11T13:06:02 | INFO | Training process finished!\n",
      "2023-10-11T13:06:02 | INFO | Calculating metrics...\n",
      "2023-10-11T13:06:02 | INFO | Full process finished in 1.85 minutes.\n",
      "2023-10-11T13:06:02 | INFO | Saving the predict function.\n",
      "2023-10-11T13:06:02 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "save_estimator_path = \"../model_files/final__base_learner.pkl\"\n",
    "base_full_logs = model_pipeline(train_df = data,\n",
    "                            validation_df = validation_df,\n",
    "                            params = params_original,\n",
    "                            target_column = target_column,\n",
    "                            features = base_features,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False,\n",
    "                            save_estimator_path=None\n",
    "                          )\n",
    "\n",
    "with open(save_estimator_path, \"wb\") as context:\n",
    "    cp.dump(base_full_logs[\"lgbm_classification_learner\"], context)\n",
    "    \n",
    "base_full_logs[\"data\"][\"oof_df\"].to_pickle(\"../data/final__base_oof_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8c72a72-7bbf-42ee-907d-82acc1a7e31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11T13:06:02 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-11T13:06:02 | INFO | Training for fold 1\n",
      "2023-10-11T13:06:29 | INFO | Training for fold 2\n",
      "2023-10-11T13:06:57 | INFO | Training for fold 3\n",
      "2023-10-11T13:07:25 | INFO | CV training finished!\n",
      "2023-10-11T13:07:25 | INFO | Training the model in the full dataset...\n",
      "2023-10-11T13:08:00 | INFO | Training process finished!\n",
      "2023-10-11T13:08:00 | INFO | Calculating metrics...\n",
      "2023-10-11T13:08:00 | INFO | Full process finished in 1.98 minutes.\n",
      "2023-10-11T13:08:00 | INFO | Saving the predict function.\n",
      "2023-10-11T13:08:00 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "save_estimator_path = \"../model_files/final__ensemble_learner.pkl\"\n",
    "ensemble_full_logs = model_pipeline(train_df = data,\n",
    "                            validation_df = validation_df,\n",
    "                            params = ensemble_params_mc,\n",
    "                            target_column = target_column,\n",
    "                            features = ensemble_features,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False,\n",
    "                            save_estimator_path=None\n",
    "                          )\n",
    "\n",
    "with open(save_estimator_path, \"wb\") as context:\n",
    "    cp.dump(ensemble_full_logs[\"lgbm_classification_learner\"], context)\n",
    "    \n",
    "ensemble_full_logs[\"data\"][\"oof_df\"].to_pickle(\"../data/final__ensemble_oof_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65da5fe9-0301-4d3b-b528-1ee068cc118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11T13:08:01 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-11T13:08:01 | INFO | Training for fold 1\n",
      "2023-10-11T13:08:49 | INFO | Training for fold 2\n",
      "2023-10-11T13:09:39 | INFO | Training for fold 3\n",
      "2023-10-11T13:10:28 | INFO | CV training finished!\n",
      "2023-10-11T13:10:28 | INFO | Training the model in the full dataset...\n",
      "2023-10-11T13:11:29 | INFO | Training process finished!\n",
      "2023-10-11T13:11:29 | INFO | Calculating metrics...\n",
      "2023-10-11T13:11:29 | INFO | Full process finished in 3.47 minutes.\n",
      "2023-10-11T13:11:29 | INFO | Saving the predict function.\n",
      "2023-10-11T13:11:29 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "save_estimator_path = \"../model_files/final__all_learner.pkl\"\n",
    "all_full_logs = model_pipeline(train_df = data,\n",
    "                            validation_df = validation_df,\n",
    "                            params = params_all,\n",
    "                            target_column = target_column,\n",
    "                            features = all_features_list,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False,\n",
    "                            save_estimator_path=None\n",
    "                          )\n",
    "with open(save_estimator_path, \"wb\") as context:\n",
    "    cp.dump(all_full_logs[\"lgbm_classification_learner\"], context)\n",
    "    \n",
    "all_full_logs[\"data\"][\"oof_df\"].to_pickle(\"../data/final__all_oof_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98a097e9-e457-4225-826d-c26bc66cb628",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predict_fn = joblib.load(\"../model_files/final__all_learner.pkl\")\n",
    "boruta_predict_fn= joblib.load(\"../model_files/final__boruta_learner.pkl\")\n",
    "fw_predict_fn= joblib.load(\"../model_files/final__fw_learner.pkl\")\n",
    "base_predict_fn= joblib.load(\"../model_files/final__base_learner.pkl\")\n",
    "ensemble_predict_fn= joblib.load(\"../model_files/final__ensemble_learner.pkl\")\n",
    "\n",
    "lpf = [\n",
    "all_predict_fn,\n",
    "boruta_predict_fn,\n",
    "fw_predict_fn, \n",
    "base_predict_fn,\n",
    "ensemble_predict_fn\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ec0bed2-8631-4e9f-a349-e65b97720965",
   "metadata": {},
   "outputs": [],
   "source": [
    "l= []\n",
    "for name, predict_fn in zip(names, lpf):\n",
    "    aux = predict_fn[\"predict_fn\"](private_df)[[space_column, \"prediction\"]].rename(columns = {\"prediction\":f\"prediction_{name}\"})\n",
    "    l.append(aux)\n",
    "df_predictions= reduce(lambda x,y:pd.merge(x,y, on = space_column), l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f752dcc-462e-4f24-9872-d85e4e810c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.loc[:,\"prediction_average\"] = df_predictions.loc[:,columns].mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28ed641c-0902-482c-8780-7550ef18a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_all = pd.read_pickle(\"../data/final__all_oof_df.pkl\")\n",
    "boruta_all = pd.read_pickle(\"../data/final__boruta_oof_df.pkl\")\n",
    "ensemble_all = pd.read_pickle(\"../data/final__ensemble_oof_df.pkl\")\n",
    "fw_all = pd.read_pickle(\"../data/final__fw_oof_df.pkl\")\n",
    "base_all = pd.read_pickle(\"../data/final__base_oof_df.pkl\")\n",
    "\n",
    "ldf = [tmp_all, boruta_all, fw_all, base_all, ensemble_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2b0c787-9cfd-4f7f-bac1-10b992f7b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "l= []\n",
    "for name, _df in zip(names, ldf):\n",
    "    aux = _df[[space_column, \"prediction\"]].rename(columns = {\"prediction\":f\"prediction_{name}\"})\n",
    "    l.append(aux)\n",
    "df_predictions_train= reduce(lambda x,y:pd.merge(x,y,on = space_column), l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84a05282-eee0-405e-87e8-67d31966f927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test set for fold 1 is :0.873\n",
      "Score on test set for fold 2 is :0.864\n",
      "Score on test set for fold 3 is :0.862\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegressionCV(cv = 3, random_state=42)\n",
    "aux = df_predictions_train.merge(data[[space_column, target_column]], on = space_column)\n",
    "result = train_binary(aux, columns, target_column, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f95a5499-2222-459d-aa78-b927c8b94b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.loc[:,\"prediction_lr\"] = result[\"model\"].predict_proba(df_predictions[columns])[:,1]\n",
    "df_predictions.rename(columns = {\"prediction\":\"prediction_lr\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e156831-c308-434f-b71c-b0b6f07afbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test set for fold 1 is :0.872\n",
      "Score on test set for fold 2 is :0.864\n",
      "Score on test set for fold 3 is :0.862\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "mlp = MLPClassifier(random_state=42,activation=\"tanh\", max_iter=300,learning_rate=\"adaptive\")\n",
    "aux = df_predictions_train.merge(data[[space_column, target_column]], on = space_column)\n",
    "result = train_binary(aux, columns, target_column, mlp)\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8d3ffd-7a4a-432d-a934-e2198a15ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.loc[:,\"prediction_mlp\"] = result[\"model\"].predict_proba(df_predictions[columns])[:,1]\n",
    "df_predictions.rename(columns = {\"prediction\":\"prediction_mlp\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "388b8c37-be3c-46e7-b264-1e2dfa83f33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test set for fold 1 is :0.872\n",
      "Score on test set for fold 2 is :0.864\n",
      "Score on test set for fold 3 is :0.862\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "estimators = [(\"tanh\",MLPClassifier(random_state=42,activation=\"tanh\", max_iter=300,learning_rate=\"adaptive\")),\n",
    "             (\"relu\", MLPClassifier(random_state=42,activation=\"relu\", max_iter=300,learning_rate=\"adaptive\")),\n",
    "             (\"sigmoid\",MLPClassifier(random_state=0,activation=\"logistic\", max_iter=300,learning_rate=\"adaptive\"))\n",
    "             ]\n",
    "model = StackingClassifier(estimators)\n",
    "aux = df_predictions_train.merge(data[[space_column, target_column]], on = space_column)\n",
    "result = train_binary(aux, columns, target_column, model)\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b12f589c-d0ea-477a-a5c7-2773ccd6a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.loc[:,\"prediction_mlp_stack\"] = result[\"model\"].predict_proba(df_predictions[columns])[:,1]\n",
    "df_predictions.rename(columns = {\"prediction\":\"prediction_mlp_stack\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da221d4-4f21-473b-9eba-2d8e6ef9b8e7",
   "metadata": {},
   "source": [
    "### Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7133469a-4c70-464e-bdc6-e780d98ab685",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/submissions/private_predictions_average_gsc_mc_selected.csv\"\n",
    "private_predictions = df_predictions[[space_column, \"prediction_average\"]]\n",
    "private_predictions = private_predictions.rename(columns = {\"prediction_average\":\"Probability\"})\n",
    "private_predictions.to_csv(path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10729e0a-1c77-4b2f-803c-13e34583f0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/submissions/private_predictions_lr_gsc_mc_selected.csv\"\n",
    "private_predictions = df_predictions[[space_column, \"prediction_lr\"]]\n",
    "private_predictions = private_predictions.rename(columns = {\"prediction_lr\":\"Probability\"})\n",
    "private_predictions.to_csv(path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "984bffc6-5ec8-49ed-9747-bcd27c10e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/submissions/private_predictions_mlp_gsc_mc_selected.csv\"\n",
    "private_predictions = df_predictions[[space_column, \"prediction_mlp\"]]\n",
    "private_predictions = private_predictions.rename(columns = {\"prediction_mlp\":\"Probability\"})\n",
    "private_predictions.to_csv(path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34da8c9e-2093-452b-8067-72e24414d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/submissions/private_predictions_mlp_stacked_gsc_mc_selected.csv\"\n",
    "private_predictions = df_predictions[[space_column, \"prediction_mlp_stack\"]]\n",
    "private_predictions = private_predictions.rename(columns = {\"prediction_mlp_stack\":\"Probability\"})\n",
    "private_predictions.to_csv(path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d470c2d-763b-49c0-ab0d-20728e5c88ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
