{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6b2ced2-45c9-4bd2-8b76-ee63a050ee4e",
   "metadata": {},
   "source": [
    "# Monotone constraints all models\n",
    "\n",
    "## Rationale:\n",
    "\n",
    "Monotone constraints showed to benefit the ``Boruta``model so we are to test whether or not this also benefits to each model.\n",
    "\n",
    "## Methodology:\n",
    "We are to define the monotone constraints for each feature i.e the direction of the relationship between feature and target in the following way:\n",
    "\n",
    "1. We are to train a linear regression model to explain target average (average risk) for every model decile.\n",
    "2. We are then to keep the trend coeficient of the model to define the constraint.\n",
    "3. The constrains may be the sign of the coreficient: ```(+ , -, 0)```\n",
    "4. Finally, we are to test the model performance of both models, the one with and without constraints.\n",
    "\n",
    "The previous methodology will be applied to all the models.\n",
    "\n",
    "## Conclusions:\n",
    "\n",
    "**Conclusions from Model Performance Table:**\n",
    "\n",
    "The results showed that this methodology did not benefit to all the models.\n",
    "\n",
    "\n",
    "| Model                      | out_of_fold | validation |\n",
    "|----------------------------|------------|------------|\n",
    "| all_features [173]         | 0.862250   | 0.866135   |\n",
    "| all_mc_features [173]      | 0.862359   | 0.867179   |\n",
    "| base_features [10]         | 0.864081   | 0.865510   |\n",
    "| base_mc_features [10]      | 0.861828   | 0.864351   |\n",
    "| ensemble_features [82]     | 0.864084   | 0.866569   |\n",
    "| ensemble_mc_features [82]  | 0.863107   | 0.866836   |\n",
    "| fw_features [53]           | 0.862487   | 0.866534   |\n",
    "| fw_mc_features [53]        | 0.862111   | 0.866872   |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc520cbf-149b-4df6-a3f7-fb647718f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lightgbm import LGBMClassifier as lgbm\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "\n",
    "import warnings;warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# local imports\n",
    "from src.learner_params import target_column, boruta_learner_params, test_params\n",
    "from utils.functions__utils import find_constraint\n",
    "\n",
    "from src.learner_params import params_all, params_ensemble, params_fw, params_original, MODEL_PARAMS\n",
    "from utils.feature_selection_lists import fw_features, boruta_features, ensemble_features\n",
    "from utils.features_lists import all_features_list, base_features\n",
    "\n",
    "from utils.functions__training import model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4dae8f-43ba-4d6c-82c3-6f66961c81c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"../data/train_df.pkl\")\n",
    "validation_df = pd.read_pickle(\"../data/validation_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d3946d-6fc4-4365-b52a-2060c62649a5",
   "metadata": {},
   "source": [
    "## Find the monotone constraints for every model\n",
    "\n",
    "We are to use the methodology based on linear model to find the constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fec46ce-1542-49c8-86ec-cbe29019e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "boruta_monotone_const_dict = {}\n",
    "for feature in boruta_features:\n",
    "    aux = find_constraint(train_df, feature, target_column)\n",
    "    boruta_monotone_const_dict[feature] = aux\n",
    "\n",
    "fw_monotone_const_dict = {}\n",
    "for feature in fw_features:\n",
    "    aux = find_constraint(train_df, feature, target_column)\n",
    "    fw_monotone_const_dict[feature] = aux\n",
    "\n",
    "ensemble_monotone_const_dict = {}\n",
    "for feature in ensemble_features:\n",
    "    aux = find_constraint(train_df, feature, target_column)\n",
    "    ensemble_monotone_const_dict[feature] = aux\n",
    "\n",
    "all_monotone_const_dict = {}\n",
    "for feature in all_features_list:\n",
    "    aux = find_constraint(train_df, feature, target_column)\n",
    "    all_monotone_const_dict[feature] = aux\n",
    "\n",
    "base_monotone_const_dict = {}\n",
    "for feature in base_features:\n",
    "    aux = find_constraint(train_df, feature, target_column)\n",
    "    base_monotone_const_dict[feature] = aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4472139a-740e-48ad-bac1-c150a6174081",
   "metadata": {},
   "outputs": [],
   "source": [
    "boruta_params = deepcopy(MODEL_PARAMS)\n",
    "boruta_params[\"learner_params\"][\"extra_params\"][\"monotone_constraints\"] = list(boruta_monotone_const_dict.values())\n",
    "\n",
    "fw_params = deepcopy(params_fw)\n",
    "fw_params[\"learner_params\"][\"extra_params\"][\"monotone_constraints\"] = list(fw_monotone_const_dict.values())\n",
    "\n",
    "ensemble_params = deepcopy(params_ensemble)\n",
    "ensemble_params[\"learner_params\"][\"extra_params\"][\"monotone_constraints\"] = list(ensemble_monotone_const_dict.values())\n",
    "\n",
    "all_params = deepcopy(params_all)\n",
    "all_params[\"learner_params\"][\"extra_params\"][\"monotone_constraints\"] = list(all_monotone_const_dict.values())\n",
    "\n",
    "base_params = deepcopy(params_original)\n",
    "base_params[\"learner_params\"][\"extra_params\"][\"monotone_constraints\"] = list(base_monotone_const_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0838c3-f864-4e5e-8a87-dd7dccebada2",
   "metadata": {},
   "source": [
    "## Train the learners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0550d2d4-89ec-48af-b596-bf857059639e",
   "metadata": {},
   "source": [
    "### Base with no constraints\n",
    "We are to train each model with the optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ca11e2-d95c-4400-8d69-9294c81553e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11T09:56:57 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-11T09:56:58 | INFO | Training for fold 1\n",
      "2023-10-11T09:58:26 | INFO | Training for fold 2\n",
      "2023-10-11T09:59:58 | INFO | Training for fold 3\n",
      "2023-10-11T10:01:33 | INFO | CV training finished!\n",
      "2023-10-11T10:01:33 | INFO | Training the model in the full dataset...\n",
      "2023-10-11T10:03:48 | INFO | Training process finished!\n",
      "2023-10-11T10:03:48 | INFO | Calculating metrics...\n",
      "2023-10-11T10:03:48 | INFO | Full process finished in 6.84 minutes.\n",
      "2023-10-11T10:03:48 | INFO | Saving the predict function.\n",
      "2023-10-11T10:03:48 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "boruta_logs = model_pipeline(train_df = train_df,\n",
    "                            validation_df = validation_df,\n",
    "                            params = MODEL_PARAMS,\n",
    "                            target_column = target_column,\n",
    "                            features = boruta_features,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb486243-d897-4e96-995b-02c225a73662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11T10:03:48 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-11T10:03:48 | INFO | Training for fold 1\n",
      "2023-10-11T10:04:27 | INFO | Training for fold 2\n",
      "2023-10-11T10:05:06 | INFO | Training for fold 3\n",
      "2023-10-11T10:05:45 | INFO | CV training finished!\n",
      "2023-10-11T10:05:45 | INFO | Training the model in the full dataset...\n",
      "2023-10-11T10:06:32 | INFO | Training process finished!\n",
      "2023-10-11T10:06:32 | INFO | Calculating metrics...\n",
      "2023-10-11T10:06:32 | INFO | Full process finished in 2.74 minutes.\n",
      "2023-10-11T10:06:32 | INFO | Saving the predict function.\n",
      "2023-10-11T10:06:32 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "fw_logs = model_pipeline(train_df = train_df,\n",
    "                            validation_df = validation_df,\n",
    "                            params = params_fw,\n",
    "                            target_column = target_column,\n",
    "                            features = fw_features,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f795b53-1e04-4108-b5af-324a77694fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11T10:06:33 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-11T10:06:33 | INFO | Training for fold 1\n",
      "2023-10-11T10:06:55 | INFO | Training for fold 2\n",
      "2023-10-11T10:07:17 | INFO | Training for fold 3\n",
      "2023-10-11T10:07:39 | INFO | CV training finished!\n",
      "2023-10-11T10:07:39 | INFO | Training the model in the full dataset...\n",
      "2023-10-11T10:08:07 | INFO | Training process finished!\n",
      "2023-10-11T10:08:07 | INFO | Calculating metrics...\n",
      "2023-10-11T10:08:07 | INFO | Full process finished in 1.58 minutes.\n",
      "2023-10-11T10:08:07 | INFO | Saving the predict function.\n",
      "2023-10-11T10:08:07 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "ensemble_logs = model_pipeline(train_df = train_df,\n",
    "                            validation_df = validation_df,\n",
    "                            params = params_ensemble,\n",
    "                            target_column = target_column,\n",
    "                            features = ensemble_features,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35206f42-e6b2-4059-8264-c1456e0d35d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11T10:08:08 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-11T10:08:08 | INFO | Training for fold 1\n",
      "2023-10-11T10:08:30 | INFO | Training for fold 2\n",
      "2023-10-11T10:08:54 | INFO | Training for fold 3\n",
      "2023-10-11T10:09:16 | INFO | CV training finished!\n",
      "2023-10-11T10:09:16 | INFO | Training the model in the full dataset...\n",
      "2023-10-11T10:09:43 | INFO | Training process finished!\n",
      "2023-10-11T10:09:43 | INFO | Calculating metrics...\n",
      "2023-10-11T10:09:43 | INFO | Full process finished in 1.60 minutes.\n",
      "2023-10-11T10:09:43 | INFO | Saving the predict function.\n",
      "2023-10-11T10:09:43 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "base_logs = model_pipeline(train_df = train_df,\n",
    "                            validation_df = validation_df,\n",
    "                            params = params_original,\n",
    "                            target_column = target_column,\n",
    "                            features = base_features,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af88972-50fb-47b2-906d-e2882245824c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11T10:09:44 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-11T10:09:44 | INFO | Training for fold 1\n",
      "2023-10-11T10:10:27 | INFO | Training for fold 2\n",
      "2023-10-11T10:11:10 | INFO | Training for fold 3\n",
      "2023-10-11T10:11:53 | INFO | CV training finished!\n",
      "2023-10-11T10:11:53 | INFO | Training the model in the full dataset...\n",
      "2023-10-11T10:12:46 | INFO | Training process finished!\n",
      "2023-10-11T10:12:46 | INFO | Calculating metrics...\n",
      "2023-10-11T10:12:46 | INFO | Full process finished in 3.04 minutes.\n",
      "2023-10-11T10:12:46 | INFO | Saving the predict function.\n",
      "2023-10-11T10:12:46 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "all_logs = model_pipeline(train_df = train_df,\n",
    "                            validation_df = validation_df,\n",
    "                            params = params_all,\n",
    "                            target_column = target_column,\n",
    "                            features = all_features_list,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf97835-0498-43c9-a10f-78910e70b252",
   "metadata": {},
   "source": [
    "### Base with constraints\n",
    "We are to train each learner function adding constraints to the already optimized hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e6b5362-989f-4b92-8f0c-19a5c95837df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11T10:12:46 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-11T10:12:46 | INFO | Training for fold 1\n",
      "2023-10-11T10:14:22 | INFO | Training for fold 2\n",
      "2023-10-11T10:15:58 | INFO | Training for fold 3\n",
      "2023-10-11T10:17:33 | INFO | CV training finished!\n",
      "2023-10-11T10:17:33 | INFO | Training the model in the full dataset...\n",
      "2023-10-11T10:19:46 | INFO | Training process finished!\n",
      "2023-10-11T10:19:46 | INFO | Calculating metrics...\n",
      "2023-10-11T10:19:46 | INFO | Full process finished in 7.01 minutes.\n",
      "2023-10-11T10:19:46 | INFO | Saving the predict function.\n",
      "2023-10-11T10:19:46 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "boruta_mc_logs = model_pipeline(train_df = train_df,\n",
    "                            validation_df = validation_df,\n",
    "                            params = boruta_params,\n",
    "                            target_column = target_column,\n",
    "                            features = boruta_features,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da074e02-3f49-4135-a101-3c280a40abf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11T10:19:47 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-11T10:19:47 | INFO | Training for fold 1\n",
      "2023-10-11T10:20:36 | INFO | Training for fold 2\n",
      "2023-10-11T10:21:25 | INFO | Training for fold 3\n",
      "2023-10-11T10:22:15 | INFO | CV training finished!\n",
      "2023-10-11T10:22:15 | INFO | Training the model in the full dataset...\n",
      "2023-10-11T10:23:16 | INFO | Training process finished!\n",
      "2023-10-11T10:23:16 | INFO | Calculating metrics...\n",
      "2023-10-11T10:23:16 | INFO | Full process finished in 3.50 minutes.\n",
      "2023-10-11T10:23:16 | INFO | Saving the predict function.\n",
      "2023-10-11T10:23:16 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "fw_mc_logs = model_pipeline(train_df = train_df,\n",
    "                            validation_df = validation_df,\n",
    "                            params = fw_params,\n",
    "                            target_column = target_column,\n",
    "                            features = fw_features,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "064f67d2-57a5-4f5d-ab15-fd56f4c9806d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11T10:23:17 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-11T10:23:17 | INFO | Training for fold 1\n",
      "2023-10-11T10:23:41 | INFO | Training for fold 2\n",
      "2023-10-11T10:24:04 | INFO | Training for fold 3\n",
      "2023-10-11T10:24:28 | INFO | CV training finished!\n",
      "2023-10-11T10:24:28 | INFO | Training the model in the full dataset...\n",
      "2023-10-11T10:24:58 | INFO | Training process finished!\n",
      "2023-10-11T10:24:58 | INFO | Calculating metrics...\n",
      "2023-10-11T10:24:59 | INFO | Full process finished in 1.70 minutes.\n",
      "2023-10-11T10:24:59 | INFO | Saving the predict function.\n",
      "2023-10-11T10:24:59 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "ensemble_mc_logs = model_pipeline(train_df = train_df,\n",
    "                            validation_df = validation_df,\n",
    "                            params = ensemble_params,\n",
    "                            target_column = target_column,\n",
    "                            features = ensemble_features,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "193b97ec-f9ed-4367-981e-2b1e79e2b10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11T10:24:59 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-11T10:24:59 | INFO | Training for fold 1\n",
      "2023-10-11T10:25:52 | INFO | Training for fold 2\n",
      "2023-10-11T10:26:44 | INFO | Training for fold 3\n",
      "2023-10-11T10:27:36 | INFO | CV training finished!\n",
      "2023-10-11T10:27:36 | INFO | Training the model in the full dataset...\n",
      "2023-10-11T10:28:42 | INFO | Training process finished!\n",
      "2023-10-11T10:28:42 | INFO | Calculating metrics...\n",
      "2023-10-11T10:28:42 | INFO | Full process finished in 3.72 minutes.\n",
      "2023-10-11T10:28:42 | INFO | Saving the predict function.\n",
      "2023-10-11T10:28:42 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "all_mc_logs = model_pipeline(train_df = train_df,\n",
    "                            validation_df = validation_df,\n",
    "                            params = all_params,\n",
    "                            target_column = target_column,\n",
    "                            features = all_features_list,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b93e764e-5ac8-40be-acae-0a4fe4619172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11T10:28:42 | INFO | Starting pipeline: Generating 3 k-fold training...\n",
      "2023-10-11T10:28:42 | INFO | Training for fold 1\n",
      "2023-10-11T10:29:06 | INFO | Training for fold 2\n",
      "2023-10-11T10:29:30 | INFO | Training for fold 3\n",
      "2023-10-11T10:29:53 | INFO | CV training finished!\n",
      "2023-10-11T10:29:53 | INFO | Training the model in the full dataset...\n",
      "2023-10-11T10:30:22 | INFO | Training process finished!\n",
      "2023-10-11T10:30:22 | INFO | Calculating metrics...\n",
      "2023-10-11T10:30:22 | INFO | Full process finished in 1.68 minutes.\n",
      "2023-10-11T10:30:22 | INFO | Saving the predict function.\n",
      "2023-10-11T10:30:22 | INFO | Predict function saved.\n"
     ]
    }
   ],
   "source": [
    "base_mc_logs = model_pipeline(train_df = train_df,\n",
    "                            validation_df = validation_df,\n",
    "                            params = base_params,\n",
    "                            target_column = target_column,\n",
    "                            features = base_features,\n",
    "                            cv = 3,\n",
    "                            random_state = 42,\n",
    "                            apply_shap = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053c4a8f-de21-4219-8f4d-ff65ba40a2de",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "We are to compare the performance of the models with vs without monotone constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7682ed53-6cec-494a-b157-dace21e2c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics  ={}\n",
    "models = [base_logs, all_logs, fw_logs, ensemble_logs]\n",
    "names = [\"base_features\", \"all_features\", \"fw_features\", \"ensemble_features\"]\n",
    "sizes = [len(base_features),len(all_features_list), len(fw_features), len(ensemble_features)]\n",
    "\n",
    "for model, name, size in zip(models, names, sizes):\n",
    "    model_metrics[f\"{name} [{size}]\"] = model[\"metrics\"][\"roc_auc\"]\n",
    "base_models_df = pd.DataFrame(model_metrics).T.sort_values(by = \"validation\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dd37e56-5d68-4ff2-a0bc-3ae515d9d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics  ={}\n",
    "models = [base_mc_logs, all_mc_logs, fw_mc_logs, ensemble_mc_logs]\n",
    "names = [\"base_mc_features\", \"all_mc_features\", \"fw_mc_features\", \"ensemble_mc_features\"]\n",
    "sizes = [len(base_features),len(all_features_list), len(fw_features), len(ensemble_features)]\n",
    "\n",
    "for model, name, size in zip(models, names, sizes):\n",
    "    model_metrics[f\"{name} [{size}]\"] = model[\"metrics\"][\"roc_auc\"]\n",
    "mc_models_df = pd.DataFrame(model_metrics).T.sort_values(by = \"validation\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dd78314-343b-421a-9689-c41f4d5e3d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>out_of_fold</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all_features [173]</th>\n",
       "      <td>0.862250</td>\n",
       "      <td>0.866135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_mc_features [173]</th>\n",
       "      <td>0.862359</td>\n",
       "      <td>0.867179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_features [10]</th>\n",
       "      <td>0.864081</td>\n",
       "      <td>0.865510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_mc_features [10]</th>\n",
       "      <td>0.861828</td>\n",
       "      <td>0.864351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_features [82]</th>\n",
       "      <td>0.864084</td>\n",
       "      <td>0.866569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_mc_features [82]</th>\n",
       "      <td>0.863107</td>\n",
       "      <td>0.866836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fw_features [53]</th>\n",
       "      <td>0.862487</td>\n",
       "      <td>0.866534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fw_mc_features [53]</th>\n",
       "      <td>0.862111</td>\n",
       "      <td>0.866872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           out_of_fold  validation\n",
       "all_features [173]            0.862250    0.866135\n",
       "all_mc_features [173]         0.862359    0.867179\n",
       "base_features [10]            0.864081    0.865510\n",
       "base_mc_features [10]         0.861828    0.864351\n",
       "ensemble_features [82]        0.864084    0.866569\n",
       "ensemble_mc_features [82]     0.863107    0.866836\n",
       "fw_features [53]              0.862487    0.866534\n",
       "fw_mc_features [53]           0.862111    0.866872"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([base_models_df, mc_models_df]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d356e-13b6-4d62-b906-ef6e03702989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
